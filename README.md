# Real time workshop

## Overview

This workshop is designed to provide hands-on experience with real-time data processing using Snowflake and Streamlit. The use case we will work with extracts real-time Bicing data, loads it to an S3 bucket, then Snowflake consumes it and transforms this data to serve a Streamlit. The final product is a real-time dashboard that indicates which stations need repair and what path should the Bicing truck follow in order to have availability of free docks and bikes.

## Crash course on real time data processing

Before starting to build our app, let's briefly define and explain some context that characterize event-driven architecture and the main difference between batch processing and real-time data processing.

### What is an event?

In the context of real-time data processing, an event refers to a specific occurrence or happening that takes place within a system or application. It represents a significant change or action that triggers the processing and analysis of data. Events can be generated by various sources such as user interactions, sensor readings, or system notifications. They typically contain relevant information about the event itself, such as timestamps, data payloads, and metadata. Real-time data processing systems are designed to capture, process, and respond to these events in a timely manner, enabling organizations to make informed decisions and take immediate actions based on the incoming data.

### What is real-time data processing?

Real time data processing is processing data as it is generated. In opposition to batch processing --where data is accumulated, and processed periodically (daily, hourly...)-- real-time data processing involves the continuous ingestion, transformation and loading of data. When data is generated we model it as an event, and using systems that are capable of reading and communicate events from and to other systems, we are able to implement such applications

[ ] explain basic concepts
[ ] provide an overview diagram of all the infrastructure

## Steps to Follow

Now that we have a grasp of some theroy, let's start building our application to process and activate Bicing data.

### Snowflake

1. **Create a Snowflake Free Account**: Before getting started, you need to create a Snowflake free account. Visit the [Snowflake website](https://www.snowflake.com/) and sign up for a free account if you don't have one already. Once you have your account provisioned, we can start to run the scripts in the next section.

2. **Run the setup and pipeline scripts**: all the SQL code necessary to build our app can be found in `/sql_scripts`.

    - `00_setup.sql`: create the database structure and change to SYSADMIN role.
    - `01_ingest_pipeline.sql`: create and configure various objects to build the ingestion pipeline that will continuously load data from S3 to Snowflake. Also ingest the static master data to the final msater table.
    - `02_transform.sql`: finally, create the final step of the pipeline where we transform the data we have loaded to serve the streamlit application.

3. **Create the views that will feed the application**: in order to simplify the application code (it's a simple streamlit front) we will create a couple of views that will store the logic to obtain our data modeled in the way the application will use it.

    - `11_V_BROKEN_DOCKERS.sql`: This view compares the total number of docks from the master data to the total number of bikes and free docks available at each station. This will be used to show which stations need dock repair.
    - `12_V_BIKE_DISTRIBUTION`: This view
    [ ] finish

**Bonus**: here we have a detailed diagram that pictures all the objects we just created and their relations.

[ ] draw the diagram

### Streamlit

Setting up the Streamlit account to have your own version of the app may take more steps as you need to connect your Streamlit account to your GitHub's.

1. **Create a Streamlit Account**: To visualize and interact with the real-time data, you will create a Streamlit account. First visit the [Streamlit website](https://www.streamlit.io/) and sign up for an account.

2. **Create a new app**:

[ ] finish explanation

## License

This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for details.
